# Coursera-Deep-Learning
The goal of setting up this repo is to make full use of Dr Andrew Ng's Deep Learning Specialization.

This repo mainly provides the following features:
1. For review purpose : A more convenient visualization of jupyter notebooks without setting up notebook server locally.
2. The references of papers which appear in the 5 courses as well as some notes about the papers
3. Nicely commented code from helper functions to project architecture as well as a guideline of how to go through them
4. Extend the project to end to end system: from data labeling to research diary
5. Utilizae git lfs to store large resnet.h5 and vgg.mat file. Now every project should run in local without problems!
6. (NEW from 2020!)To review the lecture notes more effectively, I organize all the concepts in the format of questions in order to build better deep learning fundations. If you want to collaborate on this, please message me :)

Recourse collection contributors: [Michael Wang](https://github.com/MichaelYxWang), [Richard Xu](https://github.com/richard3983), [Constantine Cheng](https://github.com/Consibic) and [Jay Xiao](https://github.com/J-Xiao)

We have also included the brilliant Chinese notes written by [Dr. Haiguang Huang](https://github.com/fengdu78) to faciliate understanding of the material.

### Course 4 Week 2 :
#### Case study - Classic Networks:
**[1]** "Gradient-based learning applied to document recognition"[[pdf]](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)

**[2]** "Very deep convolutional networks for large-scale image recognition"[[pdf]](https://arxiv.org/pdf/1409.1556.pdf)

**[3]** "ImageNet classification with deep convolutional neural networks"[[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

#### ResNets 
**[4]** "Deep residual networks for image recognition"[[pdf]](https://arxiv.org/pdf/1512.03385.pdf)
	
#### Networks in networks
**[5]** "Network in network"[[pdf]](https://arxiv.org/pdf/1312.4400.pdf)

#### Inception Network
**[6]** "Going deeper with convolutions"[[pdf]](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf)


### Course 4 Week 3 :
#### Convolutional Implementation of Sliding Windows
**[7]** "OverFeat: Integrated recognition, localization and detection using convolutional networks"[[pdf]](https://arxiv.org/pdf/1312.6229.pdf)

#### Bounding Box Predictions, Anchor Boxes, YOLO Algorithm
**[8]** "You Only Look Once"[[pdf]](https://pjreddie.com/media/files/papers/yolo.pdf)

#### Region Proposals
**[9]** "Rich feature hierarchies for accurate object detection and semantic segmentation"[[pdf]](https://arxiv.org/pdf/1312.6229.pdf)

**[10]** "Fast R-CNN"[[pdf]](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)

**[11]** "Faster R-CNN: Towards real-time object detection with region proposal networks"[[pdf]](https://arxiv.org/pdf/1506.01497.pdf)


### Course 4 Week 4 :
#### Siamese network , Face Verification and Binary Classfication
**[12]** "DeepFace closing the gap to human level performance"[[pdf]](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)

#### Triplet Loss
**[13]** "FaceNet: A unified embedding for face recognition and clustering"[[pdf]](https://arxiv.org/abs/1503.03832)

#### What are deep ConvNets Learning?
**[14]** "Visualizing and understanding convolutional networks"[[pdf]](
https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)
	
#### Cost Function, Content Cost Function, Style Cost Function
**[15]** "A neural algorithm of artistic style"[[pdf]](
https://arxiv.org/pdf/1508.06576.pdf)


### Course 5 Week 1 :
#### GRU (Gated Recurrent Unit)
**[16]** "On the Properties of Neural Machine Translation- Encoder–Decoder Approaches"[[pdf]](
https://arxiv.org/pdf/1409.1259.pdf)

**[17]** "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"[[pdf]](
https://arxiv.org/pdf/1412.3555.pdf)

#### LSTM (Long Short Term Memory)
**[18]** "Long Short Term Memory"[[pdf]](
http://www.bioinf.jku.at/publications/older/2604.pdf)


### Course 5 Week 2 :
#### Visualize word embeddings
**[19]** "Visualizing Data using t-SNE"[[pdf]](
http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)

#### Word embedding's relation to face encoding
**[20]** "DeepFace: Closing the Gap to Human-Level Performance in Face Verification"[[pdf]](
https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf?)

#### Properties of word embeddings
**[21]** "Linguistic Regularities in Continuous Space Word Representations"[[pdf]](
https://www.aclweb.org/anthology/N13-1090)

#### Neural Language Model
**[22]** "Linguistic Regularities in Continuous Space Word Representations"[[pdf]](
https://www.aclweb.org/anthology/N13-1090)

#### Word2Vec
**[23]** "Efficient Estimation of Word Representations in
Vector Space"[[pdf]](
https://arxiv.org/pdf/1301.3781.pdf)

#### Negative sampling
**[24]** "Distributed Representations of Words and Phrases
and their Compositionality"[[pdf]](
https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)

#### Glove word embedding
**[25]** "GloVe: Global Vectors for Word Representation"[[pdf]](https://nlp.stanford.edu/pubs/glove.pdf)

#### Debiasing word embeddings
**[26]** "Man is to Computer Programmer as Woman is to Homemaker?
Debiasing Word Embeddings"[[pdf]](https://arxiv.org/pdf/1607.06520.pdf)


### Course 5 Week 3 :
#### Sequence to sequence models
**[27]** "Sequence to Sequence Learning
with Neural Networks"[[pdf]](
https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)

**[28]** "Learning Phrase Representations using RNN Encoder–Decoder
for Statistical Machine Translation"[[pdf]](
https://arxiv.org/pdf/1406.1078.pdf)

#### Image Captioning
**[29]** "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)"[[pdf]](
https://arxiv.org/abs/1412.6632)

**[30]** "Show and Tell: A Neural Image Caption Generator"[[pdf]](
https://arxiv.org/pdf/1411.4555.pdf)

**[31]** "Deep Visual-Semantic Alignments for Generating Image Descriptions"[[pdf]](
https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)

#### Evaluate machine translation
**[32]** "BLEU: a Method for Automatic Evaluation of Machine Translation"[[pdf]](
https://www.aclweb.org/anthology/P02-1040.pdf)

#### Attention Model
**[33]** "Neural Machine Translation by Jointly Learning to Align and Translate"[[pdf]](
https://arxiv.org/pdf/1409.0473.pdf)

**[34]** "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"[[pdf]](
https://arxiv.org/pdf/1502.03044.pdf)

**[35]** "Attention Is All You Need"[[pdf]](
https://arxiv.org/pdf/1706.03762.pdf)


#### Speech Recognition and Trigger Word Detection
**[36]** "Connectionist Temporal Classification: Labelling Unsegmented
Sequence Data with Recurrent Neural Networks"[[pdf]](
https://www.cs.toronto.edu/~graves/icml_2006.pdf)

