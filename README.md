# Coursera-Deep-Learning
The goal of setting up this repo is to make full use of Dr Andrew Ng's Deep Learning Specialization.

This repo mainly provides the following features:
1. For review purpose : A more convenient visualization of jupyter notebooks without setting up notebook server locally.
2. The references of papers which appear in the 5 courses as well as some notes about the papers
3. Nicely commented code from helper functions to project architecture as well as a guideline of how to go through them
4. Extend the project to end to end system: from data labeling to research diary
5. (NEW!) Utilizae git lfs to store large resnet.h5 and vgg.mat file. Now every project should run in local without problems!

Recourse collection contributors: [Michael Wang](https://github.com/MichaelYxWang), [Richard Xu](https://github.com/richard3983), [Constantine Cheng](https://github.com/Consibic) and [Jay Xiao](https://github.com/J-Xiao)

We have also included the brilliant Chinese notes written by [Dr. Haiguang Huang](https://github.com/fengdu78) to faciliate understanding of the material.

### Course 4 Week 2 :
#### Case study - Classic Networks:
**[1]** "Gradient-based learning applied to document recognition"[[pdf]](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)

**[2]** "Very deep convolutional networks for large-scale image recognition"[[pdf]](https://arxiv.org/pdf/1409.1556.pdf)

**[3]** "ImageNet classification with deep convolutional neural networks"[[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

#### ResNets 
**[4]** "Deep residual networks for image recognition"[[pdf]](https://arxiv.org/pdf/1512.03385.pdf)
	
#### Networks in networks
**[5]** "Network in network"[[pdf]](https://arxiv.org/pdf/1312.4400.pdf)

#### Inception Network
**[6]** "Going deeper with convolutions"[[pdf]](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf)


### Course 4 Week 3 :
#### Convolutional Implementation of Sliding Windows
**[7]** "OverFeat: Integrated recognition, localization and detection using convolutional networks"[[pdf]](https://arxiv.org/pdf/1312.6229.pdf)

#### Bounding Box Predictions, Anchor Boxes, YOLO Algorithm
**[8]** "You Only Look Once"[[pdf]](https://pjreddie.com/media/files/papers/yolo.pdf)

#### Region Proposals
**[9]** "Rich feature hierarchies for accurate object detection and semantic segmentation"[[pdf]](https://arxiv.org/pdf/1312.6229.pdf)

**[10]** "Fast R-CNN"[[pdf]](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)

**[11]** "Faster R-CNN: Towards real-time object detection with region proposal networks"[[pdf]](https://arxiv.org/pdf/1506.01497.pdf)


### Course 4 Week 4 :
#### Siamese network , Face Verification and Binary Classfication
**[12]** "DeepFace closing the gap to human level performance"[[pdf]](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)

#### Triplet Loss
**[13]** "FaceNet: A unified embedding for face recognition and clustering"[[pdf]](https://arxiv.org/abs/1503.03832)

#### What are deep ConvNets Learning?
**[14]** "Visualizing and understanding convolutional networks"[[pdf]](
https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)
	
#### Cost Function, Content Cost Function, Style Cost Function
**[15]** "A neural algorithm of artistic style"[[pdf]](
https://arxiv.org/pdf/1508.06576.pdf)


### Course 5 Week 1 :
#### GRU (Gated Recurrent Unit)
**[16]** "On the Properties of Neural Machine Translation- Encoder–Decoder Approaches"[[pdf]](
https://arxiv.org/pdf/1409.1259.pdf)

**[17]** "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"[[pdf]](
https://arxiv.org/pdf/1412.3555.pdf)

#### LSTM (Long Short Term Memory)
**[18]** "Long Short Term Memory"[[pdf]](
http://www.bioinf.jku.at/publications/older/2604.pdf)


### Course 5 Week 2 :
#### Visualize word embeddings
**[19]** "Visualizing Data using t-SNE"[[pdf]](
http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)

#### Word embedding's relation to face encoding
**[20]** "DeepFace: Closing the Gap to Human-Level Performance in Face Verification"[[pdf]](
https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf?)

#### Properties of word embeddings
**[21]** "Linguistic Regularities in Continuous Space Word Representations"[[pdf]](
https://www.aclweb.org/anthology/N13-1090)

#### Neural Language Model
**[22]** "Linguistic Regularities in Continuous Space Word Representations"[[pdf]](
https://www.aclweb.org/anthology/N13-1090)

#### Word2Vec
**[23]** "Efficient Estimation of Word Representations in
Vector Space"[[pdf]](
https://arxiv.org/pdf/1301.3781.pdf)

#### Negative sampling
**[24]** "Distributed Representations of Words and Phrases
and their Compositionality"[[pdf]](
https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)

#### Glove word embedding
**[25]** "GloVe: Global Vectors for Word Representation"[[pdf]](https://nlp.stanford.edu/pubs/glove.pdf)

#### Debiasing word embeddings
**[26]** "Man is to Computer Programmer as Woman is to Homemaker?
Debiasing Word Embeddings"[[pdf]](https://arxiv.org/pdf/1607.06520.pdf)


### Course 5 Week 3 :
#### Sequence to sequence models
**[27]** "Sequence to Sequence Learning
with Neural Networks"[[pdf]](
https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)

**[28]** "Learning Phrase Representations using RNN Encoder–Decoder
for Statistical Machine Translation"[[pdf]](
https://arxiv.org/pdf/1406.1078.pdf)

#### Image Captioning
**[29]** "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)"[[pdf]](
https://arxiv.org/abs/1412.6632)

**[30]** "Show and Tell: A Neural Image Caption Generator"[[pdf]](
https://arxiv.org/pdf/1411.4555.pdf)

**[31]** "Deep Visual-Semantic Alignments for Generating Image Descriptions"[[pdf]](
https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)

#### Evaluate machine translation
**[32]** "BLEU: a Method for Automatic Evaluation of Machine Translation"[[pdf]](
https://www.aclweb.org/anthology/P02-1040.pdf)

#### Attention Model
**[33]** "Neural Machine Translation by Jointly Learning to Align and Translate"[[pdf]](
https://arxiv.org/pdf/1409.0473.pdf)

**[34]** "
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"[[pdf]](
https://arxiv.org/pdf/1502.03044.pdf)

**[35]** "
Attention Is All You Need"[[pdf]](
https://arxiv.org/pdf/1706.03762.pdf)

